"""
Parquet å‹ç¼©ç®—æ³•æ¯”è¾ƒç»ƒä¹ æ¨¡å—

æä¾›ä¸åŒå‹ç¼©ç®—æ³•çš„æ€§èƒ½æ¯”è¾ƒåŠŸèƒ½ã€‚
"""

import pyarrow as pa
import pyarrow.parquet as pq
import pandas as pd
import os
from typing import Dict, Any, List, Optional

from .utils import PerformanceAnalyzer


class ParquetCompressionExercise:
    """Parquet å‹ç¼©ç®—æ³•æ¯”è¾ƒç»ƒä¹ ç±»"""
    
    def __init__(self, data_df: pd.DataFrame, output_dir: str = "output"):
        """
        åˆå§‹åŒ–å‹ç¼©ç®—æ³•æ¯”è¾ƒç»ƒä¹ 
        
        Args:
            data_df: è¦æµ‹è¯•çš„æ•°æ®
            output_dir: è¾“å‡ºç›®å½•
        """
        self.df = data_df
        self.output_dir = output_dir
        self.performance_analyzer = PerformanceAnalyzer()
        self.compression_algorithms = ['SNAPPY', 'GZIP', 'LZ4', 'BROTLI', None]
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
    def test_single_compression(self, compression: Optional[str]) -> Dict[str, float]:
        """
        æµ‹è¯•å•ä¸ªå‹ç¼©ç®—æ³•çš„æ€§èƒ½
        
        Args:
            compression: å‹ç¼©ç®—æ³•åç§°
            
        Returns:
            æ€§èƒ½æŒ‡æ ‡å­—å…¸
        """
        compression_name = compression or 'NONE'
        print(f"æ­£åœ¨æµ‹è¯•å‹ç¼©ç®—æ³•ï¼š{compression_name}")
        print("-" * 40)
        
        filename = os.path.join(self.output_dir, f'data_{compression_name.lower()}.parquet')
        
        # è½¬æ¢ä¸º PyArrow è¡¨
        table = pa.Table.from_pandas(self.df)
        
        # æµ‹è¯•å†™å…¥æ€§èƒ½
        _, write_time = self.performance_analyzer.measure_time(
            pq.write_table, table, filename, compression=compression
        )
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = self.performance_analyzer.get_file_size(filename)
        
        # æµ‹è¯•è¯»å–æ€§èƒ½
        def read_table():
            return pq.read_table(filename)
        
        _, read_time = self.performance_analyzer.measure_time(read_table)
        
        print(f"å†™å…¥æ—¶é—´ï¼š{write_time:.4f} ç§’")
        print(f"è¯»å–æ—¶é—´ï¼š{read_time:.4f} ç§’")
        print(f"æ–‡ä»¶å¤§å°ï¼š{file_size:.2f} MB")
        
        return {
            'write_time': write_time,
            'read_time': read_time,
            'file_size': file_size,
            'filename': filename
        }
    
    def run_compression_exercise(self) -> Dict[str, Dict[str, float]]:
        """
        è¿è¡Œå‹ç¼©ç®—æ³•ç»ƒä¹ çš„ä¸»æ–¹æ³•
        
        Returns:
            æ‰€æœ‰å‹ç¼©ç®—æ³•çš„æ€§èƒ½æŒ‡æ ‡
        """
        print("ğŸ”„ å¼€å§‹å‹ç¼©ç®—æ³•ç»ƒä¹ ...")
        print("=" * 60)
        
        # è¿è¡Œæ‰€æœ‰å‹ç¼©ç®—æ³•æµ‹è¯•
        results = self.test_compression_algorithms()
        
        # ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨
        self.plot_compression_comparison(results)
        
        print("âœ… å‹ç¼©ç®—æ³•ç»ƒä¹ å®Œæˆï¼")
        return results
    
    def test_compression_algorithms(self, algorithms: List[str] = None) -> Dict[str, Dict[str, float]]:
        """
        æµ‹è¯•å¤šä¸ªå‹ç¼©ç®—æ³•çš„æ€§èƒ½
        
        Args:
            algorithms: è¦æµ‹è¯•çš„å‹ç¼©ç®—æ³•åˆ—è¡¨ï¼Œé»˜è®¤æµ‹è¯•æ‰€æœ‰
            
        Returns:
            æ‰€æœ‰ç®—æ³•çš„æ€§èƒ½ç»“æœ
        """
        if algorithms is None:
            algorithms = self.compression_algorithms
            
        print("=" * 60)
        print("å¼€å§‹å‹ç¼©ç®—æ³•æ¯”è¾ƒç»ƒä¹ ")
        print("=" * 60)
        
        results = {}
        
        for compression in algorithms:
            compression_name = compression or 'NONE'
            try:
                result = self.test_single_compression(compression)
                results[compression_name] = result
                print()  # ç©ºè¡Œåˆ†éš”
            except Exception as e:
                print(f"âŒ æµ‹è¯• {compression_name} æ—¶å‡ºé”™: {e}")
                print()
        
        # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
        self.display_compression_results(results)
        
        # ä¿å­˜ç»“æœ
        results_file = os.path.join(self.output_dir, 'compression_results.json')
        self.performance_analyzer.save_results(results, results_file)
        
        return results
    
    def display_compression_results(self, results: Dict[str, Dict[str, float]]) -> None:
        """
        æ˜¾ç¤ºå‹ç¼©ç®—æ³•å¯¹æ¯”ç»“æœ
        
        Args:
            results: å‹ç¼©ç®—æ³•ç»“æœå­—å…¸
        """
        print("=" * 80)
        print("å‹ç¼©ç®—æ³•æ€§èƒ½å¯¹æ¯”")
        print("=" * 80)
        
        # å‡†å¤‡æ˜¾ç¤ºæ•°æ®
        display_results = {}
        base_size = results.get('NONE', {}).get('file_size', 0)
        
        for algo, metrics in results.items():
            compression_ratio = base_size / metrics['file_size'] if metrics['file_size'] > 0 else 0
            display_results[algo] = {
                'write_time': metrics['write_time'],
                'read_time': metrics['read_time'],
                'file_size': metrics['file_size'],
                'compression_ratio': compression_ratio
            }
        
        # ä½¿ç”¨æ€§èƒ½åˆ†æå™¨æ˜¾ç¤ºç»“æœ
        self.performance_analyzer.compare_performance(display_results, "å‹ç¼©ç®—æ³•æ€§èƒ½å¯¹æ¯”")
        
        # æ˜¾ç¤ºé¢å¤–çš„åˆ†æ
        self.analyze_compression_tradeoffs(display_results)
    
    def analyze_compression_tradeoffs(self, results: Dict[str, Dict[str, float]]) -> None:
        """
        åˆ†æå‹ç¼©ç®—æ³•çš„æƒè¡¡
        
        Args:
            results: å‹ç¼©ç®—æ³•ç»“æœå­—å…¸
        """
        print("\n" + "=" * 60)
        print("å‹ç¼©ç®—æ³•æƒè¡¡åˆ†æ")
        print("=" * 60)
        
        # æ‰¾å‡ºæœ€ä½³ç®—æ³•
        best_compression = max(results.keys(), 
                             key=lambda x: results[x].get('compression_ratio', 0))
        fastest_write = min(results.keys(), 
                           key=lambda x: results[x].get('write_time', float('inf')))
        fastest_read = min(results.keys(), 
                          key=lambda x: results[x].get('read_time', float('inf')))
        
        print(f"ğŸ† æœ€ä½³å‹ç¼©æ¯”: {best_compression} "
              f"({results[best_compression]['compression_ratio']:.2f}x)")
        print(f"âš¡ æœ€å¿«å†™å…¥: {fastest_write} "
              f"({results[fastest_write]['write_time']:.4f}s)")
        print(f"âš¡ æœ€å¿«è¯»å–: {fastest_read} "
              f"({results[fastest_read]['read_time']:.4f}s)")
        
        # æ¨èç®—æ³•
        print(f"\nğŸ“‹ ç®—æ³•æ¨è:")
        print(f"â€¢ å­˜å‚¨ä¼˜å…ˆ: {best_compression} (æœ€é«˜å‹ç¼©æ¯”)")
        print(f"â€¢ å†™å…¥ä¼˜å…ˆ: {fastest_write} (æœ€å¿«å†™å…¥)")
        print(f"â€¢ è¯»å–ä¼˜å…ˆ: {fastest_read} (æœ€å¿«è¯»å–)")
        
        # å¹³è¡¡æ¨è
        balanced_scores = {}
        for algo, metrics in results.items():
            if algo == 'NONE':
                continue
            # ç»¼åˆè¯„åˆ†ï¼šå‹ç¼©æ¯”æƒé‡0.4ï¼Œå†™å…¥é€Ÿåº¦æƒé‡0.3ï¼Œè¯»å–é€Ÿåº¦æƒé‡0.3
            compression_score = metrics.get('compression_ratio', 0) / max(
                r.get('compression_ratio', 1) for r in results.values()
            )
            write_score = (1 / metrics.get('write_time', 1)) / max(
                1 / r.get('write_time', 1) for r in results.values()
            )
            read_score = (1 / metrics.get('read_time', 1)) / max(
                1 / r.get('read_time', 1) for r in results.values()
            )
            
            balanced_scores[algo] = (
                0.4 * compression_score + 0.3 * write_score + 0.3 * read_score
            )
        
        if balanced_scores:
            best_balanced = max(balanced_scores.keys(), key=lambda x: balanced_scores[x])
            print(f"â€¢ ç»¼åˆæœ€ä½³: {best_balanced} (å¹³è¡¡æ€§èƒ½)")
    
    def plot_compression_comparison(self, results: Dict[str, Dict[str, float]]) -> None:
        """
        ç»˜åˆ¶å‹ç¼©ç®—æ³•å¯¹æ¯”å›¾
        
        Args:
            results: å‹ç¼©ç®—æ³•ç»“æœå­—å…¸
        """
        try:
            import matplotlib.pyplot as plt
            
            # å‡†å¤‡æ•°æ®
            algorithms = list(results.keys())
            write_times = [results[algo]['write_time'] for algo in algorithms]
            read_times = [results[algo]['read_time'] for algo in algorithms]
            file_sizes = [results[algo]['file_size'] for algo in algorithms]
            
            # åˆ›å»ºå­å›¾
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
            
            # å†™å…¥æ—¶é—´å¯¹æ¯”
            ax1.bar(algorithms, write_times, alpha=0.7, color='skyblue')
            ax1.set_title('Write Time Comparison')
            ax1.set_ylabel('Time (seconds)')
            ax1.tick_params(axis='x', rotation=45)
            
            # è¯»å–æ—¶é—´å¯¹æ¯”
            ax2.bar(algorithms, read_times, alpha=0.7, color='lightgreen')
            ax2.set_title('Read Time Comparison')
            ax2.set_ylabel('Time (seconds)')
            ax2.tick_params(axis='x', rotation=45)
            
            # æ–‡ä»¶å¤§å°å¯¹æ¯”
            ax3.bar(algorithms, file_sizes, alpha=0.7, color='salmon')
            ax3.set_title('File Size Comparison')
            ax3.set_ylabel('Size (MB)')
            ax3.tick_params(axis='x', rotation=45)
            
            # å‹ç¼©æ¯”å¯¹æ¯”
            base_size = results.get('NONE', {}).get('file_size', max(file_sizes))
            compression_ratios = [base_size / size if size > 0 else 0 for size in file_sizes]
            ax4.bar(algorithms, compression_ratios, alpha=0.7, color='gold')
            ax4.set_title('Compression Ratio Comparison')
            ax4.set_ylabel('Compression Ratio')
            ax4.tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            plot_file = os.path.join(self.output_dir, 'compression_comparison.png')
            plt.savefig(plot_file, dpi=300, bbox_inches='tight')
            print(f"å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜åˆ°: {plot_file}")
            
            plt.show()
            
        except ImportError:
            print("âš ï¸  matplotlib æœªå®‰è£…ï¼Œè·³è¿‡å›¾è¡¨ç»˜åˆ¶")
    
    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        from .utils import cleanup_files
        patterns = [
            os.path.join(self.output_dir, 'data_*.parquet')
        ]
        cleanup_files(patterns)